<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.0//EN" "http://www.w3.org/TR/REC-html40/strict.dtd">
<HTML>
<HEAD>
<META NAME="KEYWORDS" CONTENT="Futurology, futurist,Alexander,Chislenko,sasha,enhanced reality,augmented reality,virtual reality, enhanced perception,augmented perception, intelligent filter">
<META NAME="Description" CONTENT="Essay on the perspectives of Intelligent information filters, Enhanced (Augmented) Reality and future of human perception by Alexander Chislenko">
<META NAME="AUTHOR" CONTENT="Alexander_Chislenko">
<META NAME="Publisher" CONTENT="Alexander_Chislenko">
<META HTTP-EQUIV="Reply-to" CONTENT="sasha1@netcom.com (Alexander Chislenko)">
<META HTTP-EQUIV="Content-language" CONTENT="en-US">
<META NAME="rating" CONTENT="General">
<META HTTP-EQUIV="Window-target" CONTENT="_top">
<LINK REL=HOME HREF="http://www.lucifer.com/~sasha/home.html"><!--virtual reality - enhanced reality - augmented reality - augmented perception-->
<TITLE>Intelligent Information Filters and Enhanced Reality by Alexander Chislenko  V.0.84-6</TITLE>
</HEAD>
<BODY BGCOLOR="#FFFFFF">
<FONT SIZE=2>
<STRONG><A HREF="http://www.lucifer.com/~sasha/articles/Versions.html">V. 0.84-5</A> - <DATE>15 April, 1997</DATE></STRONG>
</FONT>
<!-- Best way to print from Netscape: Set Bottom margin at 0.55", others - at 0.50"
     font: Times new Roman, size 12, fixed font: curier new, size 10 -->
<!-- Changes from 0.84: --------------
  Fixed links
<!-- Changes from 0.83: --------------
  Fixed and added links
<!-- Changes from 0.82: --------------
 Various relatively small textual changes and added links -->
<!-- Changes from 0.81: ---
Added pictures and font/color
Added a few sentences on omens.
Commented out the following piece.
Fixed up links.
*** This just commented out so far: ***
See also:
<A HREF="http://www.lucifer.com/~sasha/articles/EnhancedReality.txt">
plaintext</A> --
<A HREF="http://www.lucifer.com/~sasha/articles/EnhancedReality.rtf">RTF</A> --
<A HREF="http://www.lucifer.com/~sasha/articles/index.html">other essays</A> --
<A REL=HOME HREF="http://www.lucifer.com/~sasha/home.html"> my Home Page</A>
<BR>
<HR>
-->
<A REL=HOME HREF="http://www.lucifer.com/~sasha/home.html"><IMG SRC="http://www.lucifer.com/~sasha/graphics/sasha.gif" ALIGN=RIGHT HSPACE=4 VSPACE=3 ALT="Sasha" WIDTH=45 HEIGHT=55></A>
<H1><CENTER>Intelligent Information Filters<BR> and<BR> Enhanced Reality</CENTER></H1>

<FONT SIZE=3>
<CENTER><A REL=COPYRIGHT onMouseOver="window.status='You can conditionally copy this document'; return true" HREF="http://www.lucifer.com/~sasha/articles/Copyright.html">&copy;</A> 1996,1997
<A REL=HOME HREF="http://www.lucifer.com/~sasha/home.html">Alexander Chislenko</A>
</CENTER>
</FONT>
<H2>Preface</H2>
<DIV CLASS=Abstract ALIGN="justify">
I started to think seriously about the ideas of augmented perception and
personalized views of reality after reading a number of Internet messages
containing proposals to introduce language standards for on-line
communications. Frequently, people suggest restricting certain forms of
expression or polishing the language of the posts to make them less
offensive and more generally understandable.  While looking forward to the
advantages of improved communications, I wanted see them provided by
tools that would at the same time make the language mix of the Net more free
and diverse.
<P>
  In this article, I suggest that active information filtering technologies
may help us approach this goal for both textual and
<A HREF="http://www.yahoo.com/Computers_and_Internet/Multimedia/">multimedia</A>
information. I also pursue this concept further, discussing the introduction
of augmented perception and Enhanced Reality (ER), and share some
observations and predictions of the transformations in people's perception
of the world and themselves in the course of the technological progress.
</DIV>
<DIV CLASS=Section align="justify">
<H2>
<A name="RTFToC2"></A>
<CENTER>Text Translation and Its Consequences</CENTER>
</H2>
<IMG SRC="http://www.lucifer.com/~sasha/graphics/text.jpg" ALIGN=LEFT HSPACE=5 VSPACE=2 ALT="[IMAGE]" WIDTH=284 HEIGHT=200>
Many of us are used to having incoming e-mail filtered, decrypted, formatted
and shown in our favorite
<FONT COLOR="#FF0F0F">c</FONT><FONT COLOR="#FFFF0F">o</FONT><FONT COLOR="#0FFF0F">l</FONT><FONT COLOR="#0FFFFF">o</FONT><FONT COLOR="#0F0FFF">r</FONT><FONT COLOR="#0F0F0F">s</FONT>
and <FONT SIZE=4>f</FONT><FONT SIZE=3>o</FONT><FONT SIZE=1>N</FONT><EM><FONT SIZE=3>t</FONT></EM><FONT SIZE=4>s</FONT>.
 These techniques can be taken
further. Customization of spelling (e.g., American to British or archaic to
modern) would be a straightforward process. Relatively simple conversions
could also let you see any text with your favorite date and time formats, use
<A HREF="http://www.siouxlan.com/broyhill/guide/usefulinformation.html">
metric</A>
or British measures, implement
<A HREF="http://www.eff.org/pub/Censorship/Ratings_filters_labelling/">obscenity filters</A>,
 abbreviate or expand
<A HREF="http://www.yahoo.com/Reference/Acronyms_and_Abbreviations/">acronyms</A>,
omit or include technical formulas, personalize synonym selection
and punctuation rules, and use alternative
<A HREF="http://www.geocities.com/CapeCanaveral/4953/">numeric systems</A> and
alphabets
(including <A HREF="http://www.nor.com.au/community/sarc/phonetic.htm">phonetic</A>
and pictographic). Text could also be digested for a
given user, translated to his native language and even read aloud with
his favorite actor's voice.
<P>
  My friend Gary Bean suggested possible
implementation of &quot;clich&eacute;
translators&quot; that would explicitly convey the meaning of a sentence that is
known to the translator, but not necessarily to the reader. For example,
the phrase <EM>&quot;that's an interesting idea&quot;</EM> might be translated as
<EM>&quot;I have serious reservations about this&quot;.</EM> In the reverse operation,
words and phrases can be replaced with politically correct
<A HREF="http://work.ucsd.edu:5141/cgi-bin/http_webster?euphemism">euphemisms</A>.
<P><A NAME="hexon"></A>
  After the recent
<A HREF="http://www.cdt.org/policy/freespeech/12_21.cda.html">Communication Decency Act</A>,
Robert Carr developed a remarkable
<A HREF="http://www.lucifer.com/~sasha/refs/HexOn.html">&quot;HexOn Exon&quot;</A>
program that allows the
user to convert obscene words in the messages into the names of
the senators responsible for this Act, and vice versa.  Besides
presenting a humorous attempt to bypass the new obscenity censorship,
this program demonstrates that allocating both responsibilities
and rights for the contents of a message among multiple
authoring and filtering agencies may not be easy.
<P>
  Translation between various dialects and jargons, though difficult, should
still take less effort than the translation between different natural
languages, since only a part of message semantics has to be processed.
Good
<A HREF="http://dmoz.org/Recreation/Humor/Computer_Humor/Internet_Humor/Web_Filters/">
translation filters</A> would give &quot;linguistic minorities&quot; -- speakers
of languages ranging from
<A HREF="http://www.brookings.net/~darinaf/piglatin.html">Pig Latin</A> to
<A HREF="http://www.aleph.se/Trans/Words/e.html#E-PRIME">E-Prime</A> and
<A HREF="http://www.halcyon.com/loglan/what-is-loglan.html">Loglan</A>
-- a chance to practice
their own languages while communicating with the rest of the world.
<P>
   Some jargon filters have already been developed, and you can benefit from
them by enjoying reading
<EM>Ible-Bay</EM>, the <EM>Pig Latin</EM> version of the Bible, or using
<A HREF="http://www.rinkworks.com/dialect/">Dialectizer</a> program to convert
your English texts to Fudd or Cockney.
<P>
   Such translation agents would allow rapid linguistic and cultural
diversification, to the point where the language you use to communicate with
the world could diverge from everybody else's as far as the requirement of
general
<A HREF="http://work.ucsd.edu:5141/cgi-bin/http_webster?semantics">semantic</A>
compatibility may allow. It is interesting that today's
<A HREF="http://www.ncsa.uiuc.edu/General/Internet/WWW/HTMLPrimer.html">
HTML Guide</A>
already calls for the &quot;divorce of content from representation&quot;, suggesting
that you should focus on <EM>what</EM> you want to convey rather than on
<EM>how</EM> people will perceive it.
<P>
  Some of these features will require full-scale future
<A HREF="http://wombat.doc.ic.ac.uk/foldoc/foldoc.cgi/?artificial+intelligence">artificial intelligence</A>,
such as &quot;sentient translation programs&quot; described by
<A HREF="http://www.ugcs.caltech.edu/~phoenix/vinge/">Vernor Vinge</A>
in <A HREF="http://www.ugcs.caltech.edu/~phoenix/vinge/fire.html">
&quot;A Fire Upon The Deep&quot;</A>). In the meantime, they could be successfully
<A HREF="http://wombat.doc.ic.ac.uk/foldoc/foldoc.cgi/?emulation">emulated</A> by human agents.

<IMG SRC="http://www.lucifer.com/~sasha/graphics/farside.gif" ALIGN=RIGHT HSPACE=5 VSPACE=2 ALT="[IMAGE]" WIDTH=284 HEIGHT=392>
<P>
  Surprisingly, even translations between different measurement systems can
be difficult. For example, your automatic translator might have trouble
converting such expressions as &quot;a few inches away&quot;, &quot;the
temperature will be in the 80s&quot; or &quot;a duck with two feet&quot;. A
proficient translator might be able to convey the original meaning, but the
best approach would be to write the message in a general semantic form which
would store the information explicitly, indicating in the examples above
where the terms refer to measurements, whether you insist on the usage of the
original system, and the intended degree of precision. As long as the
language is expressive enough, it is suitable for the task - and this
requirement is purely semantic; symbol sets, syntax, grammar and everything
else can differ dramatically.
<P>
 A translation agent would interactively convert natural-language texts to
this semantic lingua franca and interpret them back according to a given user
profile. It could also reveal additional parts of the document depending on
users' interests, competence in the field, and access privileges.
<P>
   Currently, we can structure our mental images any way we want so long as
we can translate them to a common language. This has led to relatively
stable standardized languages and a great variability among minds. Likewise,
intelligent software translators could let us make our languages as liberated
as our minds and push the communication standards beyond our biological
bodies. (It really means just further <A HREF="http://www.lucifer.com/~sasha/articles/Cyborgs.html"><EM>exosomatic</EM> expansion of the
human <EM>functional</EM> body</A>, but the liberation still goes beyond the
traditional human interpretation of &quot;skin-encapsulated&quot; personal identity.)
<P>
  So will there be more variety or more standardization? Most likely both,
as flexible translation will help integrate knowledge domains currently
isolated by linguistic and terminological barriers, and at the same time
will protect linguistically adventurous intellectual excursions from the
danger of losing contact with the semantic mainland. Intelligent translators
could facilitate the development of
<A HREF="http://www.lucifer.com/~sasha/articles/ACF.html">more comprehensive semantic architectures</A>
that would make
the global body of knowledge at the same time more diverse and more coherent.
<P>
   Information may be stored and transmitted in the general semantic form.
With time, an increasing number of applications can be expected to use the
enriched representation as their native mode of operation.
<A HREF="http://wombat.doc.ic.ac.uk/foldoc/foldoc.cgi/?client">Client</A> translation
software will provide an
<A HREF="http://wombat.doc.ic.ac.uk/foldoc/foldoc.cgi/?emulation">emulation</A> of the
traditional world of &quot;natural&quot;
human interactions while humans still remain to appreciate it. The semantic
richness of the system will gradually shift away from biological brains,
just as data storage, transmission and computation have in recent history.
Humans will enjoy growing benefits from the system they launched, but at the
expense of understanding the increasingly complex &quot;details&quot; of its internal
structure, and for a while will keep playing an important role in guiding
the flow of events. Later, after the functional entities liberate themselves
from the realm of flesh that gave birth to them, the involvement of humans
in the evolutionary process will be of little interest to anybody except
humans themselves.

<H2 ALIGN=CENTER>Enhanced Multimedia</H2>
<IMG SRC="http://www.lucifer.com/~sasha/graphics/er_face.jpg" ALIGN=LEFT HSPACE=10 VSPACE=4 ALT="[IMAGE]" WIDTH=294 HEIGHT=272>
Similar image transformation techniques can be applied to
<A HREF="http://wombat.doc.ic.ac.uk/foldoc/foldoc.cgi/?multimedia">multimedia</A>
messages. Recently, a video system  was introduced
that allows you to &quot;soften the facial features&quot; of the person on the screen.
Advanced real-time video filters could remove wrinkles and pimples from your
face or from the faces of your favorite political figures, caricature their
opponents, give your mother-in-law a
<A HREF="http://www.kli.org/">Klingon</A>
<IMG SRC="http://www.lucifer.com/~sasha/graphics/worf.jpg" ALIGN=RIGHT HSPACE=5 VSPACE=4 ALT="[IMAGE]" WIDTH=150 HEIGHT=170> persona on your
video-phone, re-clothe people in your favorite fashion, and replace visual
clutter in the background with something tasteful.
<P>
   It also seems possible to augment human senses with transparent external
information pre-processors. For example, if your audio/video filters notice
an object of potential interest that fails to differ from its signal
environment enough to catch your attention, the filters can amplify or
otherwise differentiate (move, flash, change pitch, etc.) the signal
momentarily, to give you enough time to focus on the object, but not enough
to realize what triggered your attention.  In effect, you would instantly see
your name in a text or find Waldo in a puzzle as easily as you would notice
a source of loud noise or a bright light.
<P>
   While such filters do not have to be transparent, they may be a way to
provide a comfortable &quot;natural&quot; feeling of augmented perception for the
next few generations of humans, until the forthcoming integration of
technological and neural processing systems makes such
<A HREF="http://wombat.doc.ic.ac.uk/foldoc/foldoc.cgi/?kluge">kludgy</A> patches obsolete.
<P>
   Some non-transparent filters can already be found in military
applications. Called &quot;target enhancements&quot;, they allow military personnel to
see the enemy's tanks and radars nicely outlined and blinking.
<P>
   More advanced filtering techniques could put consistent dynamic edits
into the perceived world.
<P><IMG SRC="http://www.lucifer.com/~sasha/graphics/orange.gif" HSPACE=6 ALT="o" WIDTH=14 HEIGHT=14>
<STRONG>Volume controls</STRONG> could sharpen your senses by allowing
you to adjust the level of the signal or zoom in on small or distant objects.
<P><IMG SRC="http://www.lucifer.com/~sasha/graphics/orange.gif"  HSPACE=6 ALT="o" WIDTH=14 HEIGHT=14>
<STRONG>Calibration tools</STRONG> could
expand the effective spectral range of your perception by changing the
frequency of the signal to allow you to hear ultrasound or perceive X-rays
and radiowaves as visible light.
<P><IMG SRC="http://www.lucifer.com/~sasha/graphics/orange.gif" HSPACE=6 ALT="o" WIDTH=14 HEIGHT=14>
<STRONG>Conversions</STRONG> between different types of
signals may allow you, for example, to &quot;see&quot; noise as fog while enjoying
quiet, or convert radar readings from decelerating pedestrians in front of
you into images of red brake lights on their backs.
<P><IMG SRC="http://www.lucifer.com/~sasha/graphics/orange.gif" HSPACE=6 ALT="o" WIDTH=14 HEIGHT=14>
<STRONG>Artificial annotations</STRONG> to
perceived images would add text tags with names and descriptions to chosen
objects, append warning labels with skull and crossbones on boxes that emit
too much radiation, and surround angry people with red auras (serving
as a &quot;cold reading&quot; aid for wanna-be psychics).
<P><IMG SRC="http://www.lucifer.com/~sasha/graphics/orange.gif" HSPACE=6 ALT="o" WIDTH=14 HEIGHT=14>
<STRONG>Reality filters</STRONG> may help you filter all signals coming
from the world the way your <A HREF="http://cws.internet.com/32mail.html">favorite
mail reader</A> filters you messages, based on your stated preferences or
advice from your peers.  With such filters you may choose to see only the
objects that are worthy of your attention, and completely remove useless
and annoying sounds and images (such as
<A HREF="http://www.cnn.com/2000/SHOWBIZ/TV/01/25/digital.inserts/index.html">
advertisements</A>) from your view.
<P><IMG SRC="http://www.lucifer.com/~sasha/graphics/orange.gif" HSPACE=6 ALT="o" WIDTH=14 HEIGHT=14>
<STRONG>Perception utilities</STRONG> would give you additional
information in a familiar way -- project clocks, thermometers, weather maps,
and your current EKG readings upon [the image of] the wall in front of you,
or honk a virtual horn every time a car approaches you from behind.
They could also build on existing techniques that present us with recordings
of the past and forecasts of the future to help people develop an immersive
trans-temporal perception of reality.
<P><IMG SRC="http://www.lucifer.com/~sasha/graphics/orange.gif"  HSPACE=6 ALT="o" WIDTH=14 HEIGHT=14>
<STRONG>&quot;World improvement&quot;</STRONG>
enhancements could paint things in new colors, put smiles on faces, &quot;babify&quot;
figures of your incompetent colleagues, change night into day, erase shadows
and improve landscapes.
<P>
<A HREF="graphics/lamp02.jpg">
<IMG SRC="http://www.lucifer.com/~sasha/graphics/lamp01.jpg" ALIGN=RIGHT HSPACE=5 VSPACE=10 WIDTH=200 HEIGHT=150></A>
<IMG SRC="http://www.lucifer.com/~sasha/graphics/orange.gif"  HSPACE=6 ALT="o" WIDTH=14 HEIGHT=14>
Finally, completely <STRONG>artificial additions</STRONG> could project
<A HREF="http://space.sgo.fi/htmls/jpics.html">
northern lights</A>,
<A HREF="http://seds.lpl.arizona.edu/nineplanets/nineplanets/meteorites.html">
meteorites</A>,
and <A HREF="http://oposite.stsci.edu/pubinfo/pr/95/13.html">supernovas</A>
upon your view of the sky, or
populate it with flying toasters, virtualize and superimpose on the image of
the real world your favorite mythical characters and imaginary companions,
and provide other educational and recreational functions.
<P>
   I would call the resulting image of the world <STRONG>Enhanced Reality
(ER)</STRONG>.
<BR CLEAR=ALL>
<A NAME="RTFToC4"></A>
<H2><CENTER>Structure of Enhanced Reality</CENTER></H2>

One may expect that as long as there are things left to do in the
physical world, there will be interest in application of ER technology to
improve our interaction with real objects, while
<A HREF="http://www.hitl.washington.edu/projects/knowledge_base/onthenet.html">
Virtual Reality</A> (VR) in its traditional sense of pure
simulation can provide us with safe training environments and
high-<A HREF="http://wombat.doc.ic.ac.uk/foldoc/foldoc.cgi/?bandw">bandwidth</A> fiction.
Later, as ER becomes considerably augmented with
artificial enhancements, and VR incorporates a large
amount of archived and live recordings of
the physical world, the distinctions between the two technologies may blur.
<P>
<IMG SRC="http://www.lucifer.com/~sasha/graphics/clinton.gif" ALIGN=LEFT HSPACE=2 VSPACE=5 ALT="[IMAGE]" WIDTH=195 HEIGHT=260>

   Some of the interface enhancements can be made common, temporarily or
permanently, for large communities of people. This would allow people to
interact with each other using, and referring to, the ER
extensions as if they were parts of the real world, thus elevating the
ER entities from individual perceptions to parts of shared,
if not objective, reality. Some of such enhancements can follow the existing
metaphors. A person who has a reputation as a liar, could appear to have a long nose.
Entering a high-crime area, people may see the sky darken and hear distant funeral music.
Changes in global political and economic situations with possible effect on
some ethnic groups may be translated into bolts of thunder and other
culture-specific omens.
<P>
<IMG SRC="http://www.lucifer.com/~sasha/graphics/bobsign.gif" ALIGN=RIGHT HSPACE=4 VSPACE=2 ALT="[IMAGE]" WIDTH=170 HEIGHT=240>

   Other extensions could be highly individualized. It is already possible,
for example, to create personalized traffic signs. Driving by the same place,
an interstate truck driver may see a &quot;no go&quot; sign projected on his windshield,
while the driver of the car behind him will see a sign saying &quot;Bob's house -
next right&quot;. More advanced technologies may create personalized interactive
illusions that would be loosely based on reality and propelled by real
events, but would show the world the way a person wants to see it. The
transparency of the illusion would not be important, since people are
already quite good at hiding bitter or boring truths behind a veil of
pleasant illusions. Many people even believe that their entirely artificial
creations (such as music or temples) either &quot;reveal&quot; the truth of the world
to them or, in some sense, &quot;are&quot; the truth.
<A HREF="http://wombat.doc.ic.ac.uk/foldoc/foldoc.cgi/?morphing">Morphing</A>
unwashed Marines into singing angels or naked beauties would help people
reconcile their dreams with their observations.
<P>
   Personal illusions should be built with some caution however. The joy of
seeing the desired color on the traffic light in front of you may not be
worth the risk. As a general rule, the more control you want over the
environment, the more careful you should be in your choice of filters.
However, if the system creating your personal world also takes care of all
your real needs, you may feel free to live in any fairy tale you like.
<P>
   In many cases, ER may provide us with more true-to-life
information than our &quot;natural&quot; perception of reality.  It could edit out mirages, show
us our &quot;real&quot; images in a virtual mirror instead of the mirror images provided
by the real mirror, or allow to see into -- and through -- solid objects.
It could also show us many interesting phenomena that human sensors cannot
perceive directly. Giving us knowledge of these things has been a historical
role of science.  Merging the obtained knowledge with our sensory perception
of the world may be the most important task of Enhanced Reality.
<A NAME="RTFToC5"></A>
<H2><CENTER>Historical Observations</CENTER></H2>

People have been building artificial symbolic &quot;sur-realities&quot; for quite a
while now, though their artifacts (from art to music to fashions to traffic
signs) have been mostly based on the physical features of the perceived
objects. Shifting some of the imaging workload to the perception software
may make communications more balanced, flexible, powerful and inexpensive.
<P>
   With time, a growing proportion of objects of interest to an
intelligent observer will be entirely artificial, with no inherent &quot;natural&quot;
appearance. Image modification techniques then may be incorporated into
integrated object designs that would simultaneously interface with a
multitude of alternative intelligent representation
<A HREF="http://retriever.cs.umbc.edu:80/agents/">agents</A>.
<P>
<IMG SRC="http://www.lucifer.com/~sasha/graphics/hmd.gif" ALIGN=RIGHT HSPACE=4 VSPACE=3 ALT="[IMAGE]" WIDTH=83 HEIGHT=79>

  The implementation of ER extensions would vary depending on the available technology.
At the beginning, it could be a computer terminal, later a headset,
then a brain implant. The implant can be internal in more than just the
physical sense, as it can actually post- and re-process information supplied
by biological sensors and other parts of the brain. The important thing here
is not the relative functional position of the extension, but the fact of
intentional redesign of perception mechanisms -- a prelude to the era
of comprehensive conscious self-engineering. The ultimate effects of these
processes may appear quite confusing to humans, as emergence of things like
personalized reality and
<A HREF="mindage.html">fluid distributed identity</A>
could undermine their
fundamental biological and cultural assumptions regarding the world and the
self.  The resulting &quot;identity&quot; architectures will form the kernel of
<A HREF="http://www.aleph.se/Trans/">trans-human</A>
civilization.
<P>
   The advancement of human input processing beyond the skin boundary is not
a novel phenomenon. In the audiovisual domain, it started with simple optics
and hearing aids centuries ago and is now making rapid progress with all
kinds of recording, transmitting and processing machinery. With such
development, &quot;live&quot; contacts with the &quot;raw world&quot; data might ultimately
become rare, and could be considered inefficient, unsafe and even illegal.
This may seem an exaggeration, but this is exactly what has already
happened during the last few thousand years to our perception of a more
traditional resource -- food. Using nothing but one's bare hands, teeth and
stomach for obtaining, breaking up, and consuming naturally grown food is
quite unpopular in all modern societies for these very reasons. In the visual
domain, contacts with objects that have not been intentionally enhanced for
one's perception (in other words, looking at real, unmanipulated, unpainted
objects without glasses) are still rather frequent for many people, and the
process is still gaining momentum, in both usage time and the intensity of
the enhancements.
<P>
   Rapid progress of technological artifacts and still stagnant human body
construction create an imperative for continuing gradual migration
of all aspects of human functionality beyond the boundaries of the biological
body, with human
<A HREF="http://work.ucsd.edu:5141/cgi-bin/http_webster?identity">identity</A>
becoming increasingly exosomatic (non-biological).

<H2 ALIGN=CENTER>Truth vs. Convenience</H2>

Enhanced Reality could bring good news to privacy lovers.  If the filters
prove sufficiently useful to become an essential part  of  the [post]human
identity architecture, the ability to filter information about your body
and other possessions out of the unauthorized observer's view may be
implemented as a standard feature of ER client software.
In Privacy-Enhanced Reality, you can be effectively invisible.
<P>
   Of course, unless you are forced to &quot;wear glasses&quot;, you can take
them off any time and see the things the way they &quot;are&quot; (i.e.,
processed only by your biological sensors and filters that had been developed
by the blind evolutionary process for jungle conditions and obsolete
purposes). In my experience, though, people readily abandon the
&quot;truth&quot; of implementation details for the convenience of the
interface and, as long as the picture looks pleasing, have little interest in
peeking into the binary or HTML source code or studying the nature of the
physical processes they observe - or listening to those who understand them.
Most likely, your favorite window into the real world is already not the one
with the curtains - it's the one with the controls...
<P>
   Many people seem already quite comfortable with the thought that their
environment might have been purposefully created by somebody smarter than
themselves, so the construction of ER shouldn't come to them as a great
<A HREF="http://work.ucsd.edu:5141/cgi-bin/http_webster?epistemology">epistemological</A>
shock.
<P>
   Canonization of chief ER engineers (probably, well-deserved) could help
these people combine their split concepts of technology and
<A HREF="http://dir.yahoo.com/Society_and_Culture/Religion_and_Spirituality/">spirituality</A>
into the long-sought-after &quot;holistic worldview&quot;.
<CENTER>
<H2>
<A HREF="http://galen.med.virginia.edu/~pjb3s/Biofeedback.html">Biofeedback</A>
 and self-perception.</H2></CENTER>

Perception enhancements may also be used for augmenting people's view of
their favorite object of observation -- themselves. Biological evolution has
provided us with a number of important self-sensors, such as physical pain,
that supply us with information about the state of our bodies, restrict
certain actions and change our emotional states. Nature invented these for
pushing our primitive ancestors to taking actions they wouldn't be able
to select rationally. Unfortunately, pain is not a very accurate indicator
of our bodily problems.  Many serious conditions do not produce any pain
until it is too late to act. Pain focuses our attention on symptoms of the
disease rather than causes, and is non-descriptive, uncontrollable, and
often counterproductive.
<P>
   Technological advances may provide us with the informational, restrictive
and emotional functions of pain without most of the above handicaps.
Indicators of important, critical, or abnormal bodily functions could be put
on output devices such as a monitor, watch or even your skin.
It is possible to restrain your body slightly when, for example, your blood
pressure climbs too high, and to emulate other restrictive effects
of pain. It may also be possible to create &quot;artificial symptoms&quot; of some
diseases. For example, showing to a patient a graph demonstrating spectral
divergence of his alpha- and delta- rhythms that may indicate some
neurotransmitter deficiency, may not be very useful. It would be much better
to give the patient a diagnostic device that is easier to
understand and more &quot;natural-looking&quot;:

<P><EM><FONT COLOR="#00DD66">
- &quot;Hello, Doctor, my toenails turned</FONT>
<FONT COLOR="#22AA22">green</FONT><FONT COLOR="#00DD66">!&quot;</FONT>
<BR><FONT COLOR="#00DD66">
- &quot;Don't worry, it's a typical arti-symptom of the</FONT>
</EM><FONT SIZE=2 COLOR="#00DD66">XYZ</FONT>
<EM><FONT COLOR="#00DD66">condition, I'm sending you the pills&quot;.</FONT></EM>
<BR>
<FONT SIZE=2>(Actually, a watch may serve a lot better than toenails as a display.)</FONT>
<P>
   Sometimes, a direct feedback generating real pain may be implemented for
patients who do not feel it when their activities approach dangerous
thresholds. For example, a non-removable, variable-strength earclip that
would cause increasing pain in your ear when your blood sugar climbs too high
may dissuade you from having that extra piece of cake. A similar clip could
make a baby cry out for help every time its
<A HREF="http://www.med.umich.edu/lrc/cardiax/ekg.gif">EKG</A>
readings go bad.
A more ethical solution with improved communication could be provided by attaching
this clip to the <EM>doctor's</EM> ear. <FONT COLOR="#00DD66">&quot;I feel your pain...&quot;</FONT>
<P>
  Similar techniques could be used to connect inputs from external systems to
human biological receptors. Wiring exosomatic sensors to our nervous systems
may allow us to better feel our environments, and start perceiving our
technological extensions as parts of our bodies (which they already are).
On the other hand, poor performance of your company could now give you a
<EM>real</EM> pain in the neck...

<H2 ALIGN=CENTER>Distant Future</H2>

   Consequent technological advances in ER,
biofeedback and other areas will lead to further blurring of
demarcation lines between biological and technological systems,
bodies and tools, selves and possessions, personalities and
environments. These advances will eventually bring to life a world
of complex self-engineered interconnected entities that may keep
showing
<A HREF="http://wombat.doc.ic.ac.uk/foldoc/foldoc.cgi/?emulation">emulated</A>
&quot;natural&quot; environments to the few remaining
[emulations of?] &quot;natural&quot; humans, who would never look behind the
magic curtain for fear of seeing that crazy functional soup...

<A NAME="RTFToC8"></A><H2 ALIGN=CENTER>
Terminological Exercises: ER &lt;-&gt;
EP -&gt;...-&gt; IE -&gt; ?! -&gt; .
</H2>

You must realize that most ER technologies suggested in this article have
little to do with changing <EM>reality</EM> and everything to do with
changing our <EM>perception</EM> of it. Though ER techniques still change
the-world-as-we-see-it, it would be more accurate to call them EP, for Enhanced
Perception, and reserve the term ER for conceptualizing
traditional technologies. The traditional technologies
have always been aimed at improvement of human perception of the
environment, from digestion of physical objects by the stomach
(cooking) to digestion of info-features by the brain (time/clock).
Since there is hardly any functional
difference in how and at what stage the clock face and other images are added
to our view of the world, and as the technologies will increasingly intermix,
an appropriate general term may be Enhanced Interface of Self with the
Environment - and, as in the case of biofeedback, the Enhanced Interface of
Self with Self.
<P>
  With future waves of structural change dissolving the
borders between self and environment, the term may generalize into
Harmonization of Structural Interrelations. Still later, when interfaces
become so smooth and sophisticated that human-based intelligence will hardly
be able to tell where the system core ends and interface begins, we'd better just
call it Improvement of Everything. Immediately after that, we will lose any
understanding of what is going on and what constitutes an improvement, and
should not try to name things anymore. Not that it would matter much if we
did...

<H2 ALIGN=CENTER>Social Implications</H2>

We can imagine that progress in human information processing will face
some usual social difficulties.
Your angry <STRONG>&quot;Klingon&quot; relatives</STRONG>
may find unexpected allies among <STRONG>&quot;proboscically enhanced&quot;</STRONG>
(a.k.a. long-nosed) people protesting against using their alternative standard
of beauty as a negative stereotype. The <STRONG>girl next door</STRONG> may
be wary that your &quot;re-clothing&quot; filters leave her in Eve's dress.
<STRONG>Parents</STRONG> could be suspicious that their clean-looking kids
appear to each other as tattooed skin-heads or
<A HREF="graphics/devil.jpg">bloodthirsty demons</A>,
or replace their obscenity masks with the popular
&quot;Beavis and Butthead&quot; obscenity-<EM>enhancement</EM> filter. Extreme
<A HREF="http://sundry.hsc.usc.edu/naturist.html">naturalists</A> will
demand that the radiant icons of the
<A HREF="http://www.microsoft.com">Microsoft</A>
logo and <A HREF="http://www.cocacola.com">Coca-Cola</A>
bottle gracefully crossing their sky should be replaced by sentimental images
of the
<A HREF="http://seds.lpl.arizona.edu/nineplanets/nineplanets/sol.html">sun</A>
and the
<A HREF="http://seds.lpl.arizona.edu/nineplanets/nineplanets/luna.html">moon</A>
that once occupied their place.
<A HREF="http://www.lp.org/">Libertarians</A>
would lobby their governments for the &quot;freedom of impression&quot; laws, while
<A HREF="http://www.usdoj.gov/dea/index.htm">drug enforcement
agencies</A> may declare that the new perception-altering techniques are
just a technological successor of simple chemical
<A HREF="http://directory.mozilla.org/Recreation/Drugs/">drugs</A>, and should be
prohibited for not providing an <EM>approved perception</EM> of reality.
<P>
   My readers often tell me that if any version of Enhanced, Augmented or
Annotated Reality gets implemented, it might be abused by people trying to
manipulate other people's views and force perceptions upon them. I realize
that all human history is filled with people's attempts to trick themselves
and others into looking at the world through the wrong glasses, and new
powerful technologies may become very dangerous tools if placed in the wrong
hands, so adding safeguards to such projects seems more than important.
<P>
   Unfortunately though, a description of any idea sufficiently complex for
protecting the world from such disasters wouldn't fit into an article that
my contemporaries would take time to read. So I just do what I can -- clean
<EM>my</EM> glasses and observe the events -- and share some impressions.
<P>
<BR CLEAR=ALL>
<CENTER><IMG SRC="http://www.lucifer.com/~sasha/graphics/crumpled.gif" ALIGN=MIDDLE HSPACE=4 ALT="________________________________________________" WIDTH=578 HEIGHT=6></CENTER>
<BR CLEAR=ALL>
<P>
   If you are interested in my more general and long-term views on evolution
of intelligence, personhood and identity, you can access my essays
on <A HREF="http://www.lucifer.com/~sasha/articles/Cyborgs.html">
Cyborgs</A> and
<A HREF="mindage.html">Mind Age</A>
and other resources related to these topics via my Web
<STRONG>home page</STRONG> at
<A REL=HOME HREF="http://www.lucifer.com/~sasha/home.html">http://www.lucifer.com/~sasha/home.html</A>.
<P>
    I am grateful to
<A HREF="http://www.apocalypse.org/pub/u/rwhe/central.html">Ron Hale-Evans</A>,
Bill Alexander, and Gary Bean for inspiration and
discussions that helped me shape this text.
</DIV>
<BR CLEAR=ALL>
<CENTER>
<A REL=SEARCH HREF="http://www.altavista.com/cgi-bin/query?pg=aq&what=web&fmt=d&q=link%3A+lucifer.com%2F%7Esasha%2FEnhancedReality.html+AND+NOT+%28url%3A+lucifer.com%2F%7Esasha%29&r=&d0=&d1=">
<IMG SRC="http://www.lucifer.com/~sasha/graphics/bar_backlinks.gif" ALIGN=CENTER HSPACE=0 BORDER=0 ALT="Backlinks" WIDTH=140 HEIGHT=18></A>
<A HREF="guestbk/articles.html"><IMG SRC="http://www.lucifer.com/~sasha/graphics/bar_guestbook.gif" ALIGN=CENTER HSPACE=0 BORDER=0 ALT="Guestbook" WIDTH=140 HEIGHT=18></A>
<A HREF="support.html"><IMG SRC="http://www.lucifer.com/~sasha/graphics/bar_support.gif" ALIGN=CENTER HSPACE=0 BORDER=0 ALT="Support" WIDTH=140 HEIGHT=18></A>
</CENTER>
<BR CLEAR=ALL>
<DIV CLASS=Appendix ALIGN=LEFT>
<A NAME="http://www.lucifer.com/~sasha/refs"></A>
<H2 ALIGN=CENTER>Resources for exploration</H2>
<UL>
<LI>
<A HREF="http://www.glue.umd.edu/~dlrg/filter/software.html">
Freely Available Information Filtering Systems</A>
<LI><A HREF="http://www.lucifer.com/~sasha/articles/ACF.html">Automated Collaborative Filtering and Semantic Transports</A>
<LI><A HREF="http://www.cs.rochester.edu:80/u/vallino/research/AR/">Augmented Reality page</A>
<LI><A HREF="http://www.ai.mit.edu/projects/hci/hci.html">
The Intelligent Room: Intelligent Enhanced Reality</A> by
<A HREF="http://www.ai.mit.edu/people/brooks/brooks.html">Rodney Brooks</A>.
<LI><A HREF="http://www.cse.dmu.ac.uk/~cph/VRbib.html">VR bibliography</A>
<LI><A HREF="http://www.cs.unc.edu/~azuma/azuma_AR.html">Augmented Reality</A>
<LI><A HREF="http://vered.rose.utoronto.ca/">ETC Lab - Augmented and Virtual Reality Page</A>
<LI><A HREF="http://biz.onramp.net/~scroger/vreality.html">Some VR Humor</A>
<LI><A HREF="http://www.hitl.washington.edu/projects/knowledge_base/edvr/">Virtual Interface Technology References</A>
<LI><A HREF="http://www.itgateway.com/">Telepresence Research, Inc.</A>
<LI><A HREF="http://www.cs.unc.edu/~mcmillan/telep.html">UNC's Telepresence Research Group</A>
</UL>
<!-- broken part here -->
</DIV>
</BODY>
</HTML>